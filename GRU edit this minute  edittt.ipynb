{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanksghub/Minute-by-Minute-Price-prediction/blob/master/GRU%20edit%20this%20minute%20%20edittt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttn36lvBgK7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "#import all libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import sklearn\n",
        "import sklearn.preprocessing\n",
        "import datetime\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "url1 = 'https://raw.githubusercontent.com/shanksghub/Minute-by-Minute-Price-prediction/master/IBM.1Min.TradesOnly.20160128.csv'\n",
        "\n",
        "\n",
        "# import dataset \n",
        "a = pd.read_csv(url1)\n",
        "\n",
        "\n",
        "\n",
        "a.head()\n",
        "a =a.drop(columns=['Ticker','TimeBarStart','Date'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08eOYQ2rBQhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbVCNjWEADzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# data scaling (normalizing)\n",
        "def normalize_data(a):\n",
        "    min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
        "    a['FirstTradePrice'] = min_max_scaler.fit_transform(a.FirstTradePrice.values.reshape(-1,1))\n",
        "    a['HighTradePrice'] = min_max_scaler.fit_transform(a.HighTradePrice.values.reshape(-1,1))\n",
        "    a['LowTradePrice'] = min_max_scaler.fit_transform(a.LowTradePrice.values.reshape(-1,1))\n",
        "    a['LastTradePrice'] = min_max_scaler.fit_transform(a['LastTradePrice'].values.reshape(-1,1))\n",
        "    return a\n",
        "a_norm = a.copy()\n",
        "a_norm = normalize_data(a_norm)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8FlKRFTAD3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into Train, Valid & test data \n",
        "valid_set_size_percentage = 10 \n",
        "test_set_size_percentage = 10 \n",
        "seq_len = 20 # taken sequence length as 20\n",
        "def load_data(a, seq_len):\n",
        "    data_raw = a.as_matrix() \n",
        "    data = [] \n",
        "    for index in range(len(data_raw) - seq_len): \n",
        "        data.append(data_raw[index: index + seq_len])\n",
        "    data = np.array(data);\n",
        "    valid_set_size = int(np.round(valid_set_size_percentage/100*data.shape[1]));  \n",
        "    test_set_size = int(np.round(test_set_size_percentage/100*data.shape[1]));\n",
        "    train_set_size = data.shape[0] - (valid_set_size + test_set_size);\n",
        "    x_train = data[:train_set_size,:-1,:]\n",
        "    y_train = data[:train_set_size,-1,:]\n",
        "    x_valid = data[train_set_size:train_set_size+valid_set_size,:-1,:]\n",
        "    y_valid = data[train_set_size:train_set_size+valid_set_size,-1,:]\n",
        "    x_test = data[train_set_size+valid_set_size:,:-1,:]\n",
        "    y_test = data[train_set_size+valid_set_size:,-1,:]\n",
        "    return [x_train, y_train, x_valid, y_valid, x_test, y_test]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NifQs4JTAD7C",
        "colab_type": "code",
        "outputId": "4b3d0aa3-99b4-4293-d1fb-f4103c822594",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "\n",
        "x_train, y_train, x_valid, y_valid, x_test, y_test = load_data(a_norm, seq_len)\n",
        "print('x_train.shape = ',x_train.shape)\n",
        "print('y_train.shape = ', y_train.shape)\n",
        "print('x_valid.shape = ',x_valid.shape)\n",
        "print('y_valid.shape = ', y_valid.shape)\n",
        "print('x_test.shape = ', x_test.shape)\n",
        "print('y_test.shape = ',y_test.shape)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train.shape =  (388, 19, 7)\n",
            "y_train.shape =  (388, 7)\n",
            "x_valid.shape =  (2, 19, 7)\n",
            "y_valid.shape =  (2, 7)\n",
            "x_test.shape =  (2, 19, 7)\n",
            "y_test.shape =  (2, 7)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4QjlC-WAEAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "n_steps = seq_len-1 \n",
        "n_inputs = 7\n",
        "n_neurons = 2000\n",
        "n_outputs = 7\n",
        "n_layers = 20000\n",
        "learning_rate = 0.001\n",
        "batch_size = 5\n",
        "n_epochs = 10\n",
        "train_set_size = x_train.shape[0]\n",
        "test_set_size = x_test.shape[0]\n",
        "tf.reset_default_graph()\n",
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.float32, [None, n_outputs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka1hFBy8AECl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "index_in_epoch = 0;\n",
        "perm_array  = np.arange(x_train.shape[0])\n",
        "np.random.shuffle(perm_array)\n",
        "\n",
        "def get_next_batch(batch_size):\n",
        "    global index_in_epoch, x_train, perm_array   \n",
        "    start = index_in_epoch\n",
        "    index_in_epoch += batch_size \n",
        "    if index_in_epoch > x_train.shape[0]:\n",
        "        np.random.shuffle(perm_array) # shuffle permutation array\n",
        "        start = 0 # start next epoch\n",
        "        index_in_epoch = batch_size     \n",
        "    end = index_in_epoch\n",
        "    return x_train[perm_array[start:end]], y_train[perm_array[start:end]]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIm4EwhGAEHK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "da50494b-021f-4965-9901-8ffeec253a17"
      },
      "source": [
        "\n",
        "#GRU \n",
        "layers = [tf.contrib.rnn.GRUCell(num_units=n_neurons, activation=tf.nn.relu)\n",
        "          for layer in range(n_layers)] "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0815 16:19:03.576869 139755669383040 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0815 16:19:03.579262 139755669383040 deprecation.py:323] From <ipython-input-8-c5fd253fd610>:2: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG-Oil8gAENK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3912c765-9461-4f9f-e2b7-15da4c08272e"
      },
      "source": [
        "                                                                  \n",
        "multi_layer_cell = tf.contrib.rnn.MultiRNNCell(layers)\n",
        "rnn_outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
        "stacked_rnn_outputs = tf.reshape(rnn_outputs, [-1, n_neurons]) \n",
        "stacked_outputs = tf.layers.dense(stacked_rnn_outputs, n_outputs)\n",
        "outputs = tf.reshape(stacked_outputs, [-1, n_steps, n_outputs])\n",
        "outputs = outputs[:,n_steps-1,:]\n",
        "                                              "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0815 16:19:07.112535 139755669383040 deprecation.py:323] From <ipython-input-9-dbff9ab1705a>:2: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
            "W0815 16:19:07.701736 139755669383040 deprecation.py:323] From <ipython-input-9-dbff9ab1705a>:3: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "W0815 16:22:27.409625 139755669383040 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0815 16:22:27.424766 139755669383040 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:564: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0815 16:22:27.443970 139755669383040 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:574: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21bikMECAEQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cost function\n",
        "loss = tf.reduce_mean(tf.square(outputs - y))\n",
        "\n",
        "#optimizer\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate) \n",
        "training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EWcxPvMxGA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcJoFQgZAES_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "                                              \n",
        "# Fitting the model\n",
        "with tf.Session() as sess: \n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for iteration in range(int(n_epochs*train_set_size/batch_size)):\n",
        "        x_batch, y_batch = get_next_batch(batch_size) # fetch the next training batch \n",
        "        sess.run(training_op, feed_dict={X: x_batch, y: y_batch}) \n",
        "        if iteration % int(5*train_set_size/batch_size) == 0:\n",
        "            mse_train = loss.eval(feed_dict={X: x_train, y: y_train}) \n",
        "            mse_valid = loss.eval(feed_dict={X: x_valid, y: y_valid}) \n",
        "            print('%.2f epochs: MSE train/valid = %.6f/%.6f'%(\n",
        "                iteration*batch_size/train_set_size, mse_train, mse_valid))\n",
        "            \n",
        "            # Predictions\n",
        "    y_test_pred = sess.run(outputs,feed_dict={X: x_test})\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5I1-LtcAEVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    \n",
        "#checking prediction output nos \n",
        "y_test_pred.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F194mNxBAEX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# ploting the graph\n",
        "comp = pd.DataFrame({'Column1':y_test[:,1],'Column3':y_test_pred[:,1]})\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot(comp['Column1'], color='blue', label='Target')\n",
        "plt.plot(comp['Column3'], color='black', label='Prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeIQ92IjAEdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAjhz0i5AEfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}