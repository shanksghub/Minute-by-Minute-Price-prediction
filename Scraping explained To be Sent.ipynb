{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shanksghub/Minute-by-Minute-Price-prediction/blob/master/Scraping%20explained%20To%20be%20Sent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRr4DvkEcgCp",
        "colab_type": "text"
      },
      "source": [
        "# Libraries We Need\n",
        "\n",
        "we will need the package pandas_datareader.data.\n",
        "\n",
        "Our program will take in a start and end date as well as a list of tickers. \n",
        "The program will download the open, high, low, close, volume, and adjusted close prices of each stock for the specified time period.\n",
        "We will also pass in a parameter that will allow us to download all available data for each stock in our list of tickers.\n",
        "Yahoo Finance sometimes blocks IP addresses that request too much data (for instance if we passed in a list of 500 tickers) so we will create some\n",
        "conditions that pause our program automatically so it looks like we are not requesting too much data. Let's get started!\n",
        "\n",
        "Implementation\n",
        "\n",
        "We first need to import four libraries: pandas_datareader.data, os, datetime, and time.\n",
        "We use the pandas_datareader to use pandas functionality to pull data from yahoo finance. \n",
        "We will use the os module to create a directory for our stock data if it does not already exist.\n",
        "We use the datetime module to obtain the current date if the user wants to download all data, and we use the time module to pause our python program so that we do not send too many data pulling requests to yahoo finance. \n",
        "Let us first create a python file called data_scraper.py and import the four libraries as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1yQbynOcNZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas_datareader.data as web\n",
        "import os\n",
        "import datetime\n",
        "import time\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VHB0fXVcsjJ",
        "colab_type": "text"
      },
      "source": [
        "We now will create our function called download_data. \n",
        "It will take in a list of tickers, a start date, an end date, and a parameter called all_data which is optional to download all historical data for the specified ticker.\n",
        "Inside our function we need to create a count variable and set it to 1.\n",
        "Each time we download data for a stock we will update the count variable and when our count variable equals 50 it means we have made 50 requests. \n",
        "We will then let our python program sleep for 10 seconds before we pull more data. \n",
        "This is just a safety net so that yahoo finance does not restrict our access to data. \n",
        "We have an all_data variable that is set to false originally. \n",
        "If the user specifies that all_data=True then we will use the datetime module to obtain the current date and then we will reformat the datetime variable into a string that has the format month-day-year, \n",
        "which will be stored in the end variable. We will let our start be January 1, 1970 as yahoo finance supports dates that date back this far. \n",
        "The nice thing about our scraper is that say a Stock started trading on 02-05-1984, \n",
        "we can let our start variable be 01-01-1970 and our data will be pulled from the date the stock started trading.\n",
        "Our program implementation so far is as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0yJ8D0wedPt",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOYXjKKycyA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_data(tickers,start,end,all_data=False):\n",
        "    count = 1\n",
        "    if all_data==True:\n",
        "        end = datetime.datetime.now()\n",
        "        end = '%s-%s-%s' % (end.month,end.day,end.year)\n",
        "        start = '01-01-1970'\n",
        "\n",
        "    directory = 'stock_data'\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    d = {}\n",
        "    for ticker in tickers:\n",
        "        filename = directory+'/'+ticker+'.csv'\n",
        "        d[ticker] = web.DataReader(ticker,\"yahoo\",start,end)\n",
        "        d[ticker].to_csv(filename)\n",
        "        \n",
        "        count  = count + 1\n",
        "        if count % 50 == 0:\n",
        "            time.sleep(10)\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUYZq6Vdc1we",
        "colab_type": "text"
      },
      "source": [
        "We now need to update our count variable for each stock we scrape data from. \n",
        "To do this we set count = count + 1. \n",
        "We then check if count % 50 == 0 and if it is we use the time module to sleep for 10 seconds. \n",
        "This will ensure that every 50 stocks scraped we wait so that yahoo finance does not block us. \n",
        "For instance, say we passed in a list of 500 tickers. \n",
        "Then, after the first 50 tickers we would sleep for 10 seconds, after 50 more stocks we would sleep for 10 seconds, and so on. \n",
        "This is the final piece of code for our function. Our completed function looks as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPeBuwMCdGX4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "We now need to run our function. To do so we will create a list of tickers, start,\n",
        "and end date and pass these in to our download_data function. \n",
        "An example of doing so is as follows:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvu3VlNRc3MY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    tickers = ['AAPL','BAC','GILD','MSFT']\n",
        "    start = '2016-01-01'\n",
        "    end = '2016-12-21'\n",
        "    download_data(tickers,start,end,all_data=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUse19PUeWKY",
        "colab_type": "text"
      },
      "source": [
        "We can run the above code and a directory called stock_data will contain AAPL.csv, BAC.csv, \n",
        "GILD.csv, and MSFT.csv for the specified start and end dates. \n",
        "With all_data=True, all data for the stocks can be added in the in our function call as above."
      ]
    }
  ]
}